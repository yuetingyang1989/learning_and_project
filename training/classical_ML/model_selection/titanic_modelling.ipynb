{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca5af1a-03ab-43dc-9190-8e93391d8808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import re\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "#from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "#from sklearn.metrics import ndcg_score\n",
    "#from sklearn.metrics import label_ranking_average_precision_score\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cbdd90f-e7e0-45f0-9cb7-4edc525a559f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Parch  Fare  Embarked  Name_length  Has_Cabin  \\\n",
       "0         0       3    1    1      0     0         0           23          0   \n",
       "1         1       1    0    2      0     3         1           51          1   \n",
       "2         1       3    0    1      0     1         0           22          0   \n",
       "3         1       1    0    2      0     3         0           44          1   \n",
       "4         0       3    1    2      0     1         0           24          0   \n",
       "\n",
       "   FamilySize  IsAlone  Title  \n",
       "0           2        0      1  \n",
       "1           2        0      3  \n",
       "2           1        1      2  \n",
       "3           2        0      3  \n",
       "4           1        1      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train_pre.csv', index_col = 0)\n",
    "test = pd.read_csv('test_pre.csv', index_col = 0)\n",
    "gender_df = pd.read_csv('gender_submission.csv', index_col = 0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b56650e9-917e-42fd-b475-b80eac6fc134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    891.000000\n",
       "mean       0.383838\n",
       "std        0.486592\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e8d7a36-e771-4530-b42c-1ba76ea8be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Name_length</th>\n",
       "      <th>Has_Cabin</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Parch  Fare  Embarked  Name_length  Has_Cabin  \\\n",
       "0       3    1    1      0     0         0           23          0   \n",
       "1       1    0    2      0     3         1           51          1   \n",
       "2       3    0    1      0     1         0           22          0   \n",
       "3       1    0    2      0     3         0           44          1   \n",
       "4       3    1    2      0     1         0           24          0   \n",
       "\n",
       "   FamilySize  IsAlone  Title  \n",
       "0           2        0      1  \n",
       "1           2        0      3  \n",
       "2           1        1      2  \n",
       "3           2        0      3  \n",
       "4           1        1      1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train.drop('Survived', 1)\n",
    "y = train['Survived']\n",
    "X_train, X_test, y_train, y_test =  train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "559607b5-7d30-4eb3-9aa2-a9b91e5aa25b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=5\n",
    "#                         , scoring='f1_macro'  # be default score is accuracy\n",
    "                        )\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19d1c947-9fbf-40db-a222-7bc0bb159bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83 accuracy with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import preprocessing\n",
    "\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a84a2-4eb0-4662-b93f-ee5d2c7c0791",
   "metadata": {},
   "source": [
    "#### cross_validate function differs from cross_val_score in two ways <br>\n",
    "* It allows specifying multiple metrics for evaluation. <br>\n",
    "* It returns a dict containing training scores, fit-times and score-times in addition to the test score. <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d59adb9-2c64-4382-b0ca-7bb908771208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84831461, 0.8569425 , 0.84291725, 0.8513324 , 0.83730715])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "scores = cross_validate(clf, X, y,\n",
    "                       scoring='accuracy', cv=5,\n",
    "                       return_estimator=True, return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "scores['train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4078030f-4741-4408-a977-cd0758192f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84357542, 0.80898876, 0.8258427 , 0.80337079, 0.85955056])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores['test_score']\n",
    "#print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores['test_score'].mean(), scores['test_score'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96e326-27ee-49ce-80ee-16bc36457af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.811 (+/-0.049) for {'C': 1, 'kernel': 'linear'}\n",
      "0.813 (+/-0.057) for {'C': 10, 'kernel': 'linear'}\n",
      "0.811 (+/-0.049) for {'C': 100, 'kernel': 'linear'}\n",
      "0.811 (+/-0.049) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.713 (+/-0.102) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.714 (+/-0.113) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.818 (+/-0.055) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.732 (+/-0.083) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.821 (+/-0.060) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.815 (+/-0.061) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.807 (+/-0.053) for {'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.814 (+/-0.060) for {'C': 1000, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.82      0.84       168\n",
      "           1       0.71      0.77      0.74       100\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.78      0.79      0.79       268\n",
      "weighted avg       0.80      0.80      0.80       268\n",
      "\n",
      "\n",
      "# Tuning hyper-parameters for recall\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "        svm.SVC(), param_grid, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bee374d-9ae6-4564-b70a-d2bd05578daf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'RandomForestClassifier(random_state=42)' (type <class 'sklearn.ensemble._forest.RandomForestClassifier'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d58e5b2982f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# pipeline defines estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m pipe = Pipeline([\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'rf'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'clf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, steps, memory, verbose)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/recommender/lib/python3.8/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_validate_steps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    166\u001b[0m             if (not (hasattr(t, \"fit\") or hasattr(t, \"fit_transform\")) or not\n\u001b[1;32m    167\u001b[0m                     hasattr(t, \"transform\")):\n\u001b[0;32m--> 168\u001b[0;31m                 raise TypeError(\"All intermediate steps should be \"\n\u001b[0m\u001b[1;32m    169\u001b[0m                                 \u001b[0;34m\"transformers and implement fit and transform \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                                 \u001b[0;34m\"or be the string 'passthrough' \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'RandomForestClassifier(random_state=42)' (type <class 'sklearn.ensemble._forest.RandomForestClassifier'>) doesn't"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# pipeline defines estimator\n",
    "pipe = Pipeline([\n",
    "    ('rf',RandomForestClassifier(random_state = 42)),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'rf__n_estimators':[120, 140],\n",
    "    'rf__max_depth': [30, 50],\n",
    "    'rf__min_samples_split': [2,3], \n",
    "    'rf__min_samples_leaf': [3, 5],  \n",
    "    'rf__class_weight': [{0:1, 1:1}, {0:1, 1:5}, {0:1, 1:3}, 'balanced'], \n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipe, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipe.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79cbd12-82f3-4028-a1fd-42a279104f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for Random Forest\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "print(\"best parameter :\", best_parameters)\n",
    "        \n",
    "y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7a52e-1151-40c1-ac6e-928e9c267c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa64529-0c07-400b-8565-63c9deb4b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Create a based model\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
    "rf_n_estimators.append(1500)\n",
    "rf_n_estimators.append(2000)\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 55, 11)]\n",
    "# Add the default as a possible value\n",
    "rf_max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "rf_max_features = ['auto', 'sqrt', 'log2']\n",
    "\n",
    "# Criterion to split on\n",
    "rf_criterion = ['mse', 'mae']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
    "\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "rf_dist = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'bootstrap': rf_bootstrap}\n",
    "\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search= RandomizedSearchCV(estimator = clf, param_distributions = random_grid, random_state = 42\n",
    "                                ,n_iter=n_iter_search, cv = 3, verbose = 2, n_jobs = -1)\n",
    "start = time()\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "print(random_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b47e1a2-c2ad-4a20-a7f4-4eb7f699fb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best parameters: \n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 4, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 300, 'n_jobs': None, 'oob_score': True, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       168\n",
      "           1       0.77      0.75      0.76       100\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.81      0.81      0.81       268\n",
      "weighted avg       0.82      0.82      0.82       268\n",
      "\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[16:54:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best parameters: \n",
      "{'objective': 'binary:logistic', 'use_label_encoder': True, 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'gpu_id': -1, 'importance_type': 'gain', 'interaction_constraints': '', 'learning_rate': 0.03, 'max_delta_step': 0, 'max_depth': 1, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 300, 'n_jobs': 8, 'num_parallel_tree': 1, 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None, 'seed': 0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85       168\n",
      "           1       0.74      0.75      0.75       100\n",
      "\n",
      "    accuracy                           0.81       268\n",
      "   macro avg       0.80      0.80      0.80       268\n",
      "weighted avg       0.81      0.81      0.81       268\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from time import time\n",
    "\n",
    "grid_n_estimator = [10, 50, 100, 300]\n",
    "grid_ratio = [.1, .25, .5, .75, 1.0]\n",
    "grid_learn = [.01, .03, .05, .1, .25]\n",
    "grid_max_depth = [2, 4, 6, 8, 10, None]\n",
    "grid_min_samples = [5, 10, .03, .05, .10]\n",
    "grid_criterion = ['gini', 'entropy']\n",
    "grid_bool = [True, False]\n",
    "grid_seed = [0]\n",
    "\n",
    "model_list = [\n",
    "    ('rfc', RandomForestClassifier())\n",
    "    ,('xgb', XGBClassifier() )\n",
    "]\n",
    "\n",
    "param_lib = [\n",
    " \n",
    "            #http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier\n",
    "          [{'n_estimators': grid_n_estimator, #default=10\n",
    "            'criterion': grid_criterion, #default=”gini”\n",
    "            'max_depth': grid_max_depth, #default=None\n",
    "            'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n",
    "            'random_state': grid_seed \n",
    "           }],\n",
    "    \n",
    "            #http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "          [{\n",
    "            #XGBClassifier - http://xgboost.readthedocs.io/en/latest/parameter.html\n",
    "            'learning_rate': grid_learn, #default: .3\n",
    "            'max_depth': [1,2,4,6,8,10], #default 2\n",
    "            'n_estimators': grid_n_estimator, \n",
    "            'seed': grid_seed  \n",
    "             }]   \n",
    "\n",
    "        ]\n",
    "\n",
    "n_iter_search = 20\n",
    "for model, param in zip(model_list, param_lib):\n",
    "    grid_search= GridSearchCV(estimator = model[1], param_grid = param\n",
    "                               ,cv = 5, verbose = 2, n_jobs = -1)\n",
    "    start = time()\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    print('Best parameters: ')\n",
    "#    for param_name in sorted(param.keys()):\n",
    "#        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    print(best_parameters)    \n",
    "    y_true, y_pred = y_test, grid_search.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbc0132-8638-4b38-96d5-44590544a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "class HyperModel : \n",
    "    def __init(self, model_type = 'classification', model_name = 'random_forest'\n",
    "               , model_tuning = 'None', **kwargs):\n",
    "        self.model = None\n",
    "        self.model_type = model_type # 'classification', 'regression'\n",
    "        self.model_name = model_name\n",
    "        self.model_tuning = model_tuning\n",
    "        self.set_model(model_type, model_name, kwargs)\n",
    "    \n",
    "    def _set_model(self, model_type, model_name, kwargs):\n",
    "        if model_type == 'classification':\n",
    "            if model_name == 'random_forest':\n",
    "                self.model = RandomForestClassifier()\n",
    "        elif model_type == 'regression':\n",
    "            if model_name == 'random_forest':\n",
    "                self.model = RandomForestRegressor(**{key:val for key, val in kwargs.items()\n",
    "                                                  if key in ['n_estimators', 'max_depth',\n",
    "                                                             'max_features', 'min_samples_leaf',\n",
    "                                                             'min_samples_split',\n",
    "                                                             'n_jobs']})\n",
    "        else:\n",
    "            raise ValueError(f'{model_type} not supported')   \n",
    "    def _tune_model(self, model_type, model_name, model_tuning, kwargs):\n",
    "        if model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96804ccf-6065-4994-a2e0-0e8dfb9aa3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class HyperModel :\n",
    "    def __init__(self, model_type = 'classification', model_name = 'random_forest', **kwargs):\n",
    "        self.model = None\n",
    "        self.model_type = model_type # 'classification', 'regression'\n",
    "        self.model_name = model_name\n",
    "        self.set_model(model_type, kwargs)\n",
    "        \n",
    "    def _set_model(self, model_type, kwargs):\n",
    "        if model_type == 'classification':\n",
    "            if model_type == 'xgboost':\n",
    "            self.model = XGBClassifier(**{key:val for key, val in kwargs.items()\n",
    "                                         if key in ['n_estimators', 'max_depth',\n",
    "                                                    'learning_rate', 'gamma',\n",
    "                                                    'n_jobs']})\n",
    "            elif model_type == 'random_forest':\n",
    "                self.model = RandomForestClassifier(**{key:val for key, val in kwargs.items()\n",
    "                                                      if key in ['n_estimators', 'max_depth',\n",
    "                                                                 'max_features', 'min_samples_leaf',\n",
    "                                                                 'min_samples_split',\n",
    "                                                                 'n_jobs']})\n",
    "            else:\n",
    "                raise ValueError(f'{model_name} not supported')\n",
    "\n",
    "        elif model_type == 'regression':\n",
    "            if model_name == 'random_forest':\n",
    "                self.model = RandomForestRegressor(**{key:val for key, val in kwargs.items()\n",
    "                                                  if key in ['n_estimators', 'max_depth',\n",
    "                                                             'max_features', 'min_samples_leaf',\n",
    "                                                             'min_samples_split',\n",
    "                                                             'n_jobs']})\n",
    "        else:\n",
    "            raise ValueError(f'{model_type} not supported')\n",
    "            \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        return self.model.fit(X, y, **kwargs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        params =  self.model.get_params(deep)\n",
    "        params['model_type'] = self.model_type\n",
    "        return params\n",
    "    \n",
    "     def set_params(self, **params):\n",
    "        if params:\n",
    "            self.model_type = params['model_type']\n",
    "            del params['model_type']\n",
    "            self._set_model(self.model_type, params)\n",
    "\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b5ab13d-f14b-488d-bc69-c6324d07f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "# parameter ranges are specified by one of below\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "#from hyper_model import HyperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df523e-4bfa-4a2c-a0b4-6fec2bd40fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
