{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "import pickle\n",
    "import datetime as dt\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# machine learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__author__ = 'yueting.yang.tue@gmail.com'\n",
    "APP_NAME = 'rank_predict_car_ads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "\n",
    "def text_pre_processing(text):\n",
    "     #remove punctuation\n",
    "    text = remove_punctuation(text)\n",
    "    \n",
    "    #lowercase & remove extra whitespace\n",
    "    text = \" \".join(text.lower().split()) \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    \n",
    "    data['src_ad_id'] = data['src_ad_id'].apply(lambda x: '{:.0f}'.format(x))\n",
    "    data['group'].fillna('no_test', inplace=True)\n",
    "    # remove null values \n",
    "    data = data[(data['telclicks'].isnull()== False) & (data['price'].isnull()== False)\\\n",
    "          &(data['model'].isnull()== False) & (data['aantalstoelen'].isnull()== False)]\n",
    "    \n",
    "    \n",
    "    # for emissie is null, it is mostly electrical cars, so we fill in emissie as 0 and energy label as A\n",
    "    data['energielabel'] = np.where(data['emissie'].isna(), 'A', data['energielabel'])\n",
    "    data['emissie']= pd.to_numeric(data['emissie'], errors='coerce')\n",
    "    data['emissie'].fillna(0, inplace=True)\n",
    "    \n",
    "    \n",
    "    data['date'] = pd.to_datetime(data['ad_start_dt'])\n",
    "    data['day_of_week'] = data['date'].dt.day_name()\n",
    "    data['days_before_cyber_monday'] = (dt.datetime(2016,11,28) - data['date']).dt.days\n",
    "    \n",
    "    \n",
    "    data['auto_age'] = 2016 - data['bouwjaar']\n",
    "    data['has_view'] = np.where(((data['telclicks']==0) & (data['bids']==0)\\\n",
    "                             & (data['n_asq']==0 ) & (data['webclicks']==0)), 0, 1)\n",
    "    data['nr_view']= data['telclicks'] + data['bids'] + data['n_asq'] + data['webclicks']\n",
    "    \n",
    "    \n",
    "    # test preprocessing for model field to combine the same filed\n",
    "    data['model_pro']= data['model'].apply(lambda text: text_pre_processing(text))\n",
    "       \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_categorical_feature(data):\n",
    "    # total number of doors\n",
    "    col = 'aantaldeuren'\n",
    "    conditions = [data[col] =='1', (data[col].isin(['2','3'])), (data[col].isin(['4','5'])), (data[col].isin(['6','7','8']))]                                                                     \n",
    "    choices = [\"1door\",\"2_3door\",\"4_5door\",'6+door']\n",
    "    data['nr_door'] = np.select(conditions, choices, default = \"Unknown\")\n",
    "    \n",
    "    # total number of chairs\n",
    "    col = 'aantalstoelen'\n",
    "    conditions = [data[col] =='1', (data[col].isin(['2','3'])), (data[col].isin(['4','5'])), (data[col].isin(['6','7','8','9']))]                                                                     \n",
    "    choices = [\"1chair\",\"2_3chair\",\"4_5chair\",'6+chair']\n",
    "    data['nr_chair'] = np.select(conditions, choices, default = \"Unknown\")\n",
    "\n",
    "    # photo counts\n",
    "    col = 'photo_cnt'\n",
    "    conditions = [data[col] <8, (data[col]>= 8) & (data[col]<= 12),(data[col]>= 13) & (data[col]<= 23)]                                                                     \n",
    "    choices = [\"max_7_foto\",\"8_12_foto\",\"13_23_foto\"]\n",
    "    data['nr_foto'] = np.select(conditions, choices, default = \"24_foto\")\n",
    "    data['nr_foto'].value_counts()\n",
    "    \n",
    "    # ads post dates\n",
    "    col = 'days_live'\n",
    "    conditions = [data[col]==0, data[col]==1, (data[col] >1) & (data[col]<= 7),(data[col] >7) & (data[col]<= 31) ]\n",
    "    choices = [\"today\",\"yesterday\",\"1_week\",\"1_month\"]\n",
    "    data['days_post'] = np.select(conditions, choices, default = \"always\")\n",
    "    \n",
    "    # brand and nations\n",
    "    col = 'brand'\n",
    "    conditions = [data[col].isin(['VOLKSWAGEN', 'BMW', 'MERCEDES','OPEL','AUDI','MERCEDES-BENZ'])\n",
    "                 , data[col].isin(['PEUGEOT','RENAULT','CITROEN'])\n",
    "                 , data[col].isin(['FORD','CHEVROLET','CHRYSLER'])\n",
    "                 , data[col].isin(['VOLVO','SAAB'])\n",
    "                 , data[col].isin(['TOYOTA','NISSAN','SUZUKI','MAZDA','MITSUBISHI','HONDA','DAIHATSU'])\n",
    "                 , data[col].isin(['SEAT'])\n",
    "                 , data[col].isin(['HYUNDAI','KIA','DAEWOO'])\n",
    "                 , data[col].isin(['SKODA'])\n",
    "                 , data[col].isin(['MINI','LAND ROVER'])\n",
    "                 ]\n",
    "    choices = [\"german\",\"french\",\"american\",\"swedish\",\"japanese\",\"spanish\",\"korean\",\"czech\",\"british\"]\n",
    "    data['brand_nation'] = np.select(conditions, choices, default = \"unknown\")\n",
    "    data['brand'] = np.where(data['brand']=='MERCEDES-BENZ', 'MERCEDES', data['brand'])\n",
    "    \n",
    "    # l2 is related to auto driving option\n",
    "    data['l2_modified'] = np.where(data['l2']=='None', 0, data['l2'])\n",
    "    data['has_auto_driving'] = np.where(data['l2']=='None', 0, 1)\n",
    "    data['l2_modified']= pd.to_numeric(data['l2_modified'], errors='coerce')\n",
    "    \n",
    "    # engine power\n",
    "    col = 'vermogen'\n",
    "    conditions = [data[col]<75, (data[col] >75) & (data[col]<= 100)\n",
    "                  ,(data[col] >100) & (data[col]<= 125) ,(data[col] >125) & (data[col]<= 150) \n",
    "                 ,(data[col] >150) & (data[col]<= 200)]\n",
    "    choices = [\"<75pk\",\"75-100pk\",\"101-125pk\",\"126-150pk\",\"151-200pk\"]\n",
    "    data['vermogen_group'] = np.select(conditions, choices, default = \">200pk\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Assumption: kmstand is related to bouwjaar and the size of the car ( imagine the size of the car represent the usage frequency)\n",
    "    data['has_kmstand'] = np.where(data['kmstand']>0, 1, 0)\n",
    "    data['kmstand_pro'] = data.groupby(['bouwjaar', 'nr_door'])['kmstand'].transform(lambda x: x.fillna(x.median()))\n",
    "    data['new_auto']= np.where((data['kmstand']<100) & (data['kmstand']>0), 1, 0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_split(df, ratio = 0.8)\n",
    "    msk = np.random.rand(len(df)) < ratio\n",
    "    train_df = df[msk]\n",
    "    test_df = df[~msk]\n",
    "    \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "def leave_one_out_encoding(df, cols, target_col):\n",
    "\n",
    "    col_encoder = ce.LeaveOneOutEncoder(cols =cols)\n",
    "    col_encoder.fit(df[cols], df[target_col])\n",
    "    \n",
    "    return col_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_array(train_df, test_df, target_col):\n",
    "    X_train = train_df.drop([target_col], axis=1).values\n",
    "    y_train = train_df[target_col].values\n",
    "\n",
    "    X_test = test_df.drop([target_col], axis=1).values\n",
    "    y_test = test_df[target_col].values\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn import gaussian_process\n",
    "from sklearn import linear_model\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn import discriminant_analysis\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "def model_selection(X_train, X_test, y_train, y_test):\n",
    "    MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "    ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    \n",
    "    #Naives Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "\n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "\n",
    "    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n",
    "    XGBClassifier(),\n",
    "    \n",
    "    #LightGBM\n",
    "    lgb.LGBMClassifier()\n",
    "    ]\n",
    "    \n",
    "    MLA_columns = ['MLA Name', 'MLA Parameters','Train ROC AUC','ROC AUC', 'F1-Score' ]\n",
    "    MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "\n",
    "    #index through MLA and save performance to table\n",
    "    row_index = 0\n",
    "    for alg in MLA:\n",
    "\n",
    "        #set name and parameters\n",
    "        MLA_name = alg.__class__.__name__\n",
    "        MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "        MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "\n",
    "        alg.fit(X_train, y_train)\n",
    "        y_train_pred = alg.predict(X_train)\n",
    "        y_pred = alg.predict(X_test)\n",
    "\n",
    "        roc_auc_train = roc_auc_score(y_train, y_train_pred)   \n",
    "        MLA_compare.loc[row_index, 'Train ROC AUC'] = roc_auc_train\n",
    "\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)   \n",
    "        MLA_compare.loc[row_index, 'ROC AUC'] = roc_auc\n",
    "\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        MLA_compare.loc[row_index, 'F1-Score'] = f1\n",
    "\n",
    "        row_index+=1\n",
    "    \n",
    "    MLA_compare.sort_values(by = ['F1-Score'], ascending = False, inplace = True)\n",
    "\n",
    "    return MLA_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(best_model_name, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    for alg in MLA:\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    if MLA_name == best_model_name\n",
    "        model = alg\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_test, y_pred)\n",
    "    score = f1_score(y_test, y_pred, average='weighted')\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('Starting')\n",
    "    print('Reading data from csv file')\n",
    "    data = pd.read_csv(\"Car_dataset.csv\") \n",
    "    \n",
    "    print('Data Cleaning')\n",
    "    data = data_cleaning(data)\n",
    "    \n",
    "    print('Select data from group B')\n",
    "    df = data[data['group']== 'B']\n",
    "    target_list = ['src_ad_id', 'telclicks', 'bids','n_asq','webclicks',\n",
    "                   'group','l2','ad_start_dt','date','nr_view','model'\n",
    "                   ,'bouwjaar','aantaldeuren','aantalstoelen','photo_cnt','kmstand']\n",
    "\n",
    "    df = df.loc[:, ~df.columns.isin(target_list)]\n",
    "\n",
    "    print('Feature Engineering')\n",
    "    print('Feature Engineering step 1: Bining categorical features')\n",
    "    df = bin_categorical_feature(df)\n",
    "    \n",
    "    \n",
    "    print('Feature Engineering step 2: Leave one out categorical features')\n",
    "    train_df, test_df =  train_test_data_split(df, 0.8)\n",
    "    cols = ['kleur','carrosserie','energielabel', 'brand', 'day_of_week'\n",
    "            ,'nr_door', 'nr_chair', 'nr_foto', 'brand_nation','days_post', 'vermogen_group','model_pro']\n",
    "    target_col = 'has_view'\n",
    "    encoder = leave_one_out_encoding(train_df, cols, target_col)\n",
    "\n",
    "    train_df[cols]= encoder.transform(train_df[cols])\n",
    "    test_df[cols] = encoder.transform(test_df[cols])\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_array(train_df, test_df, target_col)\n",
    "    \n",
    "    \n",
    "    print('Feature Engineering Finished.')\n",
    "    print('Model Selection')\n",
    "    MLA_compare = model_selection(X_train, X_test, y_train, y_test)\n",
    "    best_model_name = MLA_compare.iloc[0]['MLA Name']\n",
    "    print('Best model is: ',best_model_name)\n",
    "    print('Best model  ROC AUC %.3f' % MLA_compare.iloc[0]['ROC AUC'])\n",
    "    print('Best model  F1-Score %.3f' % MLA_compare.iloc[0]['F1-Score'])\n",
    "    \n",
    "   \n",
    "    print('Model Prediction & Evaluation')\n",
    "    y_pred = model_training(best_model_name, X_train, X_test, y_train, y_test)\n",
    "    test_df['prediction'] = y_pred\n",
    "    score = evaluation(y_test, y_pred)\n",
    "\n",
    "    # save the model to disk\n",
    "    filename = 'lgb_model.sav'\n",
    "    pickle.dump(cl, open(filename, 'wb'))\n",
    "    test_df.to_csv('prediction.csv')\n",
    "    print('Model Prediction Finished and Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
