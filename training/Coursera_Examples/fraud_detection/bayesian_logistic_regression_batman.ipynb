{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Modeling of Registration-time Fake Hotel Detection for Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian modeling of registration-time fake hotel detection\n",
    "The idea here is to make a model that predicts whether a newly registrated property is fake while quantifying the **epistemic uncertainty** of the prediction. In other words: we want the model **to know when it doesn't know**. \n",
    "\n",
    "This is achieved by applying Variational Bayes Logistic Regression, where each of the weights of the model are themselves a represented by a Normal distribution instead of being just a scalar number. The mean and variance of the Normal distribution of each normal distribution is learned from the data. This results in a situation where, if there is low uncertainty about the model weights, the variances will shrink to zero. At prediction time, the model will generate a distribution of model scores for each instance rather than a single prediction. This means that we can generate multiple predictions for the same instance by sampling from the weight distributions and applying these sampled weights to make a prediction. When a prediction is made that was in a dense-part of the feature space in the training set, we expect the model to generate narrow prediction intervals. When a prediction is made for an instance that was unlike any instance in the training set, we expect the model to generate wide prediction intervals, representing the uncertainty of the generated prediction.\n",
    "\n",
    "This is hypothesized to have several possible use cases:\n",
    "\n",
    "- if the model's uncertainty grows over time, then this can possibly be used as a measure of the degree to which the model is impacted by concept drift\n",
    "- the model's uncertainty could then be used as a measure for when the model needs to be retrained\n",
    "- the uncertain predictions of the model could be send to fraud operations team for manual investigation as a form of active learning\n",
    "\n",
    "This notebook takes several steps:\n",
    "\n",
    "- it trains a [lightGBM](https://lightgbm.readthedocs.io/en/latest/) model to learn the complex feature-interactions that we need in fraud detection\n",
    "- we use this lightGBM model to transform each instance of the Batman data into so-called **leaf-node assignment**, i.e., for each instance on which it predicts it creates a one-hot-encoded vector for each tree of the lightGBM tree-ensemble that indicates to which leaf-node of this tree this instance belongs. The one-hot-encoded vectors of the individual trees are concatenated to create a vector of zero-and-ones as a learned feature representation of the instance based on the whole tree ensemble.\n",
    "- it fits a Variational Bayes logistic regression on top of the leaf-node assignments.\n",
    "- we measure the uncertainty of the predictions, and show that instances that signed up a long time after the model had been trained had more uncertainty than instances that signed up just after the model had been trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as sf\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "tfd = tfp.distributions\n",
    "tfpl = tfp.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just some data plumbing & pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batman_pd = (\n",
    "    spark.table(\"counterfraud.batman_model_features_and_labels\")\n",
    "    .where(sf.col('signup_finished_at')>='2019-06-01')\n",
    "    .toPandas()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sort data by signup date to create a stream that would resemble reality\n",
    "# use mergesort as it is a stable sort (unlike the default quicksort)\n",
    "batman_pd.sort_values(\"signup_finished_at\", kind=\"mergesort\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# all the feature columns in the Batman dataset are prefixed with \"property_\"\n",
    "feature_cols = [col for col in batman_pd if col.startswith('property__')]\n",
    "\n",
    "X = batman_pd[feature_cols]\n",
    "y = batman_pd[\"is_fake_hotel\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_training_data(X):\n",
    "    \"\"\"\n",
    "    Pre-processes feature vectors by:\n",
    "    - filling None and NaN values with -1\n",
    "    - label_encoding categorical variables\n",
    "\n",
    "    Our dataset contains no features that naturally take take the value -1,\n",
    "    so this will effectively allow the tree to seperate our None/NaNs from\n",
    "    other values\n",
    "\n",
    "    In our normal model training pipeline, H2O takes care of null values\n",
    "    and handling of categorical variables. With lightgbm we need\n",
    "    to do that ourselves.\n",
    "    \"\"\"\n",
    "    categorical_feature_indices = [i for i, x in enumerate(X.dtypes) if x == \"object\"]\n",
    "    if categorical_feature_indices:\n",
    "        preprocess_categorical_features(X, categorical_feature_indices)\n",
    "    # preprocess NaN values in numeric features, as skmultiflow's learners can't handle them\n",
    "    X.fillna(-1, inplace=True)\n",
    "    return X\n",
    "\n",
    "\n",
    "def preprocess_categorical_features(df, indices):\n",
    "    # fill None or NaN values\n",
    "    df.iloc[:, indices] = df.iloc[:, indices].fillna(\"\")\n",
    "    # LabelEncode categorical features\n",
    "    df.iloc[:, indices] = df.iloc[:, indices].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batman_pd[feature_cols] = preprocess_training_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batman_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batman_data_daterange(date_start, date_end):\n",
    "    # Just a helper function to get the Batman instances of a given date range\n",
    "    return batman_pd[(batman_pd[\"signup_finished_at\"] >= date_start) \n",
    "                     & (batman_pd[\"signup_finished_at\"] < date_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_lightgbm_dataset(data):\n",
    "    # Just a helper function to get some Batman instances in the format that LightGBM likes\n",
    "    return lightgbm.Dataset(data[feature_cols], label=data[\"is_fake_hotel\"], categorical_feature=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    # parameters as found in: https://vizier.booking.com/dashboard/studies/2428\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'boosting': 'gbdt',\n",
    "    \"max_depth\": 13,\n",
    "    \"learning_rate\": 0.024782155042265455,\n",
    "    \"reg_alpha\": 0.2927510698213333,\n",
    "    \"reg_lambda\": 0.2509836997410686,\n",
    "    \"colsample_bytree\": 0.6481804503911828,\n",
    "    \"min_child_weight\": 67,\n",
    "    \"num_iterations\": 25,\n",
    "}\n",
    "\n",
    "model = lightgbm.train(parameters,\n",
    "                       to_lightgbm_dataset(batman_data_daterange(\"2020-04-01\", \"2020-08-01\")),\n",
    "                       valid_sets=to_lightgbm_dataset(batman_data_daterange(\"2020-08-01\", \"2020-09-01\")),\n",
    "                       num_boost_round=5000,\n",
    "                       early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaf_node_assignments = model.predict(\n",
    "    batman_data_daterange(\"2020-04-01\", \"2020-09-01\")[feature_cols],\n",
    "    pred_leaf=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oh_enc = OneHotEncoder(\n",
    "    handle_unknown='ignore',\n",
    "    sparse=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oh_enc.fit(leaf_node_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oh_leaf_nodes = oh_enc.transform(leaf_node_assignments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Variational Bayes Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_dense_variational_layer(prior_fn, posterior_fn, data):\n",
    "    dense_variational_layer = tfpl.DenseVariational(\n",
    "        input_shape=(data.shape[1],),\n",
    "        units=2,\n",
    "        make_prior_fn=prior_fn,\n",
    "        make_posterior_fn=posterior_fn,\n",
    "        kl_weight=1 / data.shape[0],\n",
    "        kl_use_exact=False,\n",
    "    )\n",
    "    return dense_variational_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The spike-and-slab prior\n",
    "We will use a so-called \"spike and slab\" (also called a *scale mixture prior*) distribution as the prior distribution for the model weights. This distribution has a density that is the weighted sum of two normally distributed ones: one with a standard deviation of 1 and one with a standard deviation of 10. In this way, it has a sharp spike around 0 (from the normal distribution with standard deviation 1), but is also more spread out towards far away values (from the contribution from the normal distribution with standard deviation 10). The reason for using such a prior is that it is like a standard unit normal, but makes values far away from 0 more likely, allowing the model to explore a larger weight space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to define the spike and slab distribution\n",
    "def spike_and_slab(event_shape, dtype):\n",
    "    distribution = tfd.Mixture(\n",
    "        cat=tfd.Categorical(probs=[0.5, 0.5]),\n",
    "        components=[\n",
    "            tfd.Independent(tfd.Normal(\n",
    "                loc=tf.zeros(event_shape, dtype=dtype), \n",
    "                scale=1.0*tf.ones(event_shape, dtype=dtype)),\n",
    "                            reinterpreted_batch_ndims=1),\n",
    "            tfd.Independent(tfd.Normal(\n",
    "                loc=tf.zeros(event_shape, dtype=dtype), \n",
    "                scale=10.0*tf.ones(event_shape, dtype=dtype)),\n",
    "                            reinterpreted_batch_ndims=1)],\n",
    "    name='spike_and_slab')\n",
    "    return distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot what the spike-and-slab distribution looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_plot = np.linspace(-5, 5, 1000)[:, np.newaxis]\n",
    "plt.plot(x_plot, tfd.Normal(loc=0, scale=1).prob(x_plot).numpy(), label='unit normal', linestyle='--')\n",
    "plt.plot(x_plot, spike_and_slab(1, dtype=tf.float32).prob(x_plot).numpy(), label='spike and slab')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Density')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_prior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    prior_model = tf.keras.Sequential([\n",
    "        tfpl.DistributionLambda(lambda t: spike_and_slab(n, dtype=dtype))\n",
    "    ])\n",
    "    return prior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_posterior(kernel_size, bias_size, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    posterior_model = tf.keras.Sequential([\n",
    "        tfpl.VariableLayer(tfp.layers.IndependentNormal.params_size(n), dtype=dtype),\n",
    "        tfp.layers.IndependentNormal(n),\n",
    "    ])\n",
    "    return posterior_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def nll(y_true, y_pred):\n",
    "    return -y_pred.log_prob(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dense_variational_layer = get_dense_variational_layer(get_prior, get_posterior, oh_leaf_nodes)\n",
    "\n",
    "bayesian_fake_hotel_model = Sequential([\n",
    "    dense_variational_layer,\n",
    "    tfpl.OneHotCategorical(2, convert_to_tensor_fn=tfd.Distribution.mode)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesian_fake_hotel_model.compile(loss=nll,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'],\n",
    "              experimental_run_tf_function=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesian_fake_hotel_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = batman_data_daterange(\"2020-04-01\", \"2020-09-01\")[\"is_fake_hotel\"].to_numpy()\n",
    "y = y.reshape((y.shape[0], 1))\n",
    "gt_oh_enc = OneHotEncoder(\n",
    "    sparse=False\n",
    ")\n",
    "y = gt_oh_enc.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bayesian_fake_hotel_model.fit(x=oh_leaf_nodes, y=y, epochs=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyse_model_prediction(data, true_labels, model, instance_idx, run_ensemble=False):\n",
    "    num_classes = 2\n",
    "    if run_ensemble:\n",
    "        ensemble_size = 200\n",
    "    else:\n",
    "        ensemble_size = 1\n",
    "    image = data[instance_idx]\n",
    "    true_label = int(true_labels[instance_idx, 1])\n",
    "    predicted_probabilities = np.empty(shape=(ensemble_size, num_classes))\n",
    "    for i in range(ensemble_size):\n",
    "        predicted_probabilities[i] = model(image[np.newaxis, :]).mean().numpy()[0]\n",
    "    model_prediction = model(image[np.newaxis, :])\n",
    "    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(10, 2),\n",
    "                                   gridspec_kw={'width_ratios': [2, 4]})\n",
    "    \n",
    "    # Show the label\n",
    "    ax1.axis('off')\n",
    "    ax1.set_title('True label: {}'.format(str(true_label)))\n",
    "    \n",
    "    # Show a 95% prediction interval of model predicted probabilities\n",
    "    pct_2p5 = np.array([np.percentile(predicted_probabilities[:, i], 2.5) for i in range(num_classes)])\n",
    "    pct_97p5 = np.array([np.percentile(predicted_probabilities[:, i], 97.5) for i in range(num_classes)])    \n",
    "    bar = ax2.bar(np.arange(num_classes), pct_97p5, color='red')\n",
    "    bar[int(true_label)].set_color('green')\n",
    "    ax2.bar(np.arange(num_classes), pct_2p5-0.02, color='white', linewidth=1, edgecolor='white')\n",
    "    ax2.set_xticks(np.arange(num_classes))\n",
    "    ax2.set_ylim([0, 1])\n",
    "    ax2.set_ylabel('Probability')\n",
    "    ax2.set_title('Model estimated probabilities')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_interval(model, data, instance_idx, num_samples=200):\n",
    "    \"\"\"\n",
    "    This method returns the mean prediction and the width of the 95% prediction interval\n",
    "    \"\"\"\n",
    "    num_classes = 2\n",
    "    image = data[instance_idx]    \n",
    "    predicted_probabilities = np.empty(shape=(num_samples, num_classes))\n",
    "    for i in range(num_samples):\n",
    "        predicted_probabilities[i] = model(image[np.newaxis, :]).mean().numpy()[0]\n",
    "\n",
    "    pct_2p5 = np.percentile(predicted_probabilities[:, 1], 2.5)\n",
    "    pct_97p5 = np.percentile(predicted_probabilities[:, 1], 97.5)\n",
    "    interval_width = pct_97p5 - pct_2p5\n",
    "    pred_mean = np.mean(predicted_probabilities[:, 1])\n",
    "    return pred_mean, interval_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    analyse_model_prediction(oh_leaf_nodes, y, bayesian_fake_hotel_model, i, run_ensemble=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation time to construct the 95% prediction interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, the CI-width is instance-dependent, which looks nice. But it also took a time. Let's time how quickly we can make our predictions. We now use the prediction_interval-method, to make sure that we're really measuring the time that it takes to construct the 95%-prediction CI and not measuring the time that is taking to plot (as opposed to analyse_model_prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the prediction time scale in the number of samples-per-prediction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, i, num_samples=1) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, i, num_samples=10) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, i, num_samples=50) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, i, num_samples=100) for i in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would expect, the predictions scale linearly in the number samples-per-prediction. Taking 200 samples per prediction took 35.9 seconds to make 10 predictions, and this took 18.1 seconds when taking 100 samples per prediction. This yields 0.01795 seconds-per-predictions-per-sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the prediction time scale in the number of instances?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, i) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, i) for i in range(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we would expect, the predictions also scale linearly in the number of predictions. Making 10 predictions takes 36 seconds, resulting in 3.6 seconds per prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What if we would vectorize this?\n",
    "Each time that we make one call to the Bayesian model, the model weights get sampled from the model's posterior distribution over its weights. This means that if we predict for different instances in the same model-call, these predictions will get made using the exact same model weights. This is no problem. \n",
    "\n",
    "But when we want to sample predictions for a single instance from the posterior predictive distribution, we need the Bayesian model weights to be sampled again from the model's posterior distribution over its weights. Otherwise, if we would re-use the same Bayesian model weights to generate another prediction on the same instance, that prediction would end up being the same again and we would effectively end up re-generating the same sample from the posterior predictive distribution instead of generating a new one. Thus, multiple predictions for the same instance need to be generated through independent calls to the model if we want these predictions to be different from eachother.\n",
    "\n",
    "For this reason, we are able to vectorize over the instance-dimension, but we are not able to vectorize over the posterior-predictive-sample-dimension. The latter dimension we will need to keep doing with a for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prediction_interval_vectorized(model, data, instance_idx, num_samples=200):\n",
    "    \"\"\"\n",
    "    This method returns the mean prediction and the width of the 95% prediction interval.\n",
    "    In contrast to **prediction_interval**, this implementation vectorizes the compute over the instance\n",
    "    dimension. Pass an array of instance_idx, and the output will be the and array of prediction means and \n",
    "    prediction interval widths for those instances.\n",
    "    \"\"\"\n",
    "    num_instances = len(instance_idx)\n",
    "    image = data[instance_idx]\n",
    "    predicted_probabilities = np.empty(shape=(num_samples, num_instances))\n",
    "    for i in range(num_samples):\n",
    "        predicted_probabilities[i,:] = model(image).mean().numpy()[:,1]\n",
    "    \n",
    "    pct_2p5 = np.array([np.percentile(predicted_probabilities[:, i], 2.5) for i in range(num_instances)])\n",
    "    pct_97p5 = np.array([np.percentile(predicted_probabilities[:, i], 95.5) for i in range(num_instances)])\n",
    "    interval_width = pct_97p5 - pct_2p5\n",
    "    pred_mean = np.array([np.mean(predicted_probabilities[:, i]) for i in range(num_instances)])\n",
    "    return pred_mean, interval_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit prediction_interval_vectorized(bayesian_fake_hotel_model, oh_leaf_nodes, range(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit prediction_interval_vectorized(bayesian_fake_hotel_model, oh_leaf_nodes, range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%timeit prediction_interval_vectorized(bayesian_fake_hotel_model, oh_leaf_nodes, range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many samples-per-prediction do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first 6 predictions there are 2 with reasonably large spread: instance 3 and 5 (0-indexed). Let's see how the spread of those two predictions is affected by sampling more (or less)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ci_width_for_instance(instance_idx):\n",
    "    sample_sizes = [2 ** i for i in range(10)]\n",
    "    ci_width = [\n",
    "        [prediction_interval(bayesian_fake_hotel_model, oh_leaf_nodes, instance_idx, num_samples=size)[1] for i in range(10)]\n",
    "        for size in sample_sizes\n",
    "    ]\n",
    "    ci_width_pd = pd.DataFrame(\n",
    "        {\"number_of_samples\": [sample_sizes[i] for i in range(len(sample_sizes)) for _ in range(10)],\n",
    "         \"ci_width\": [item for sublist in ci_width for item in sublist],\n",
    "        })\n",
    "    sns.lineplot(\n",
    "        data=ci_width_pd,\n",
    "        x=\"number_of_samples\",\n",
    "        y=\"ci_width\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_ci_width_for_instance(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sizes = [2 ** i for i in range(10)]\n",
    "ci_width = np.concatenate([\n",
    "    prediction_interval_vectorized(bayesian_fake_hotel_model, oh_leaf_nodes, [3], num_samples=size)[1] for i in range(10)\n",
    "    for size in sample_sizes\n",
    "], axis=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ci_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ci_width_for_instance_vectorized(instance_idx):\n",
    "    sample_sizes = [2 ** i for i in range(10)]\n",
    "    ci_width = np.concatenate([\n",
    "        prediction_interval_vectorized(bayesian_fake_hotel_model, oh_leaf_nodes, instance_idx, num_samples=size)[1] for i in range(10)\n",
    "        for size in sample_sizes\n",
    "    ], axis=None)\n",
    "    ci_width_pd = pd.DataFrame(\n",
    "        {\"number_of_samples\": [sample_sizes[i] for i in range(len(sample_sizes)) for _ in range(10)],\n",
    "         \"ci_width\": ci_width,\n",
    "        })\n",
    "    sns.lineplot(\n",
    "        data=ci_width_pd,\n",
    "        x=\"number_of_samples\",\n",
    "        y=\"ci_width\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_ci_width_for_instance_vectorized([3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uncertainty quantification using entropy\n",
    "\n",
    "We can also calculate some aggregated statistic that captures the uncertainty of a models predictions across a dataset of several predictions, instead of for individual predictions. One way to do this is to calculate the [entropy](https://en.wikipedia.org/wiki/Entropy_%28information_theory%29) of the distribution. The entropy is the expected information (or informally, the expected 'surprise') of a random variable, and is a measure of the uncertainty of the random variable. The entropy of the estimated probabilities for sample $i$ is defined as\n",
    "\n",
    "$$\n",
    "H_i = -\\sum_{j=1}^{2} p_{ij} \\text{log}_{2}(p_{ij})\n",
    "$$\n",
    "\n",
    "where $p_{ij}$ is the probability that the model assigns to sample $i$ corresponding to label $j$. The entropy as above is measured in _bits_. If the natural logarithm is used instead, the entropy is measured in _nats_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_correct_indices(model, x, labels):\n",
    "    y_model = model(x)\n",
    "    correct = np.argmax(y_model.mean(), axis=1) == np.squeeze(labels)\n",
    "    correct_indices = [i for i in range(x.shape[0]) if correct[i]]\n",
    "    incorrect_indices = [i for i in range(x.shape[0]) if not correct[i]]\n",
    "    return correct_indices, incorrect_indices\n",
    "\n",
    "\n",
    "def plot_entropy_distribution(model, x, labels):\n",
    "    probs = model(x).mean().numpy()\n",
    "    entropy = -np.sum(probs * np.log2(probs), axis=1)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for i, category in zip(range(2), ['Correct', 'Incorrect']):\n",
    "        entropy_category = entropy[get_correct_indices(model, x, labels)[i]]\n",
    "        mean_entropy = np.mean(entropy_category)\n",
    "        num_samples = entropy_category.shape[0]\n",
    "        title = category + 'ly labelled ({:.1f}% of total)'.format(num_samples / x.shape[0] * 100)\n",
    "        axes[i].hist(entropy_category, weights=(1/num_samples)*np.ones(num_samples))\n",
    "        axes[i].annotate('Mean: {:.3f} bits'.format(mean_entropy), (0.4, 0.9), ha='center')\n",
    "        axes[i].set_xlabel('Entropy (bits)')\n",
    "        axes[i].set_ylim([0, 1])\n",
    "        axes[i].set_ylabel('Probability')\n",
    "        axes[i].set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_entropy_distribution(model, x, labels):\n",
    "    probs = model(x).mean().numpy()\n",
    "    entropy = -np.sum(probs * np.log2(probs), axis=1)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for i, category in zip(range(2), ['Correct', 'Incorrect']):\n",
    "        entropy_category = entropy[get_correct_indices(model, x, labels)[i]]\n",
    "        mean_entropy = np.mean(entropy_category)\n",
    "        num_samples = entropy_category.shape[0]\n",
    "        title = category + 'ly labelled ({:.1f}% of total)'.format(num_samples / x.shape[0] * 100)\n",
    "        axes[i].hist(entropy_category, weights=(1/num_samples)*np.ones(num_samples))\n",
    "        axes[i].annotate('Mean: {:.3f} bits'.format(mean_entropy), (0.4, 0.9), ha='center')\n",
    "        axes[i].set_xlabel('Entropy (bits)')\n",
    "        axes[i].set_ylim([0, 1])\n",
    "        axes[i].set_ylabel('Probability')\n",
    "        axes[i].set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ci_width_distribution(model, x, labels):\n",
    "    preds_with_cis = prediction_interval_vectorized(\n",
    "        model, x, instance_idx=range(len(x))\n",
    "    )\n",
    "    ci_widths = preds_with_cis[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for i, category in zip(range(2), ['Correct', 'Incorrect']):\n",
    "        ci_widths_category = ci_widths[get_correct_indices(model, x, labels)[i]]\n",
    "        mean_ci_width = np.mean(ci_widths_category)\n",
    "        num_samples = ci_widths_category.shape[0]\n",
    "        title = category + 'ly labelled ({:.1f}% of total)'.format(num_samples / x.shape[0] * 100)\n",
    "        axes[i].hist(ci_widths_category, weights=(1/num_samples)*np.ones(num_samples))\n",
    "        axes[i].annotate('Mean 95%-CI-width: {:.3f}'.format(mean_ci_width), (0.4, 0.9), ha='center')\n",
    "        axes[i].set_xlabel('95%-CI-width')\n",
    "        axes[i].set_ylim([0, 1])\n",
    "        axes[i].set_ylabel('Probability')\n",
    "        axes[i].set_title(title)       \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_entropy_distribution(bayesian_fake_hotel_model, oh_leaf_nodes, [elem[1] for elem in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows that the model was much more uncertain about its incorrect predictions than about its correct predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_on_timerange(\n",
    "    start_date,\n",
    "    end_date,\n",
    "    measure\n",
    "):\n",
    "    # create one-hot-encoded leaf-node-assignments\n",
    "    leaf_node_assignments = model.predict(batman_data_daterange(start_date, end_date)[feature_cols], pred_leaf=True)\n",
    "    one_hot_leaf_nodes = oh_enc.transform(leaf_node_assignments)\n",
    "\n",
    "    # labels\n",
    "    y = batman_data_daterange(start_date, end_date)[\"is_fake_hotel\"].to_numpy()\n",
    "    y_one_hot = y.reshape((-1, 1))\n",
    "    y_one_hot = gt_oh_enc.transform(y_one_hot)\n",
    "\n",
    "    if measure == \"entropy\":\n",
    "        plot_entropy_distribution(bayesian_fake_hotel_model, one_hot_leaf_nodes, y)\n",
    "    elif measure == \"ci_width\":\n",
    "        plot_ci_width_distribution(bayesian_fake_hotel_model, one_hot_leaf_nodes, y)\n",
    "    else:\n",
    "        raise ValueError(f\"Evaluation measure {measure} is unknown.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate the entropy on the month just after training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2020-09-01\", \"2020-10-01\", measure=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for comparison, we now evaluate the entropy on the data from 3 months later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2020-12-01\", \"2021-01-01\", measure=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2021-01-01\", \"2021-02-01\", measure=\"entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2021-02-01\", \"2021-03-01\", measure=\"entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how over time the entropy of the predictions increased a little bit: \n",
    "\n",
    "- from 0.596 to 0.639 for the incorrect predictions\n",
    "- from 0.286 to 0.314 for the correct predictions\n",
    "\n",
    "Remember that entropy is a measure of **how wide** the uncertainty intervals around the prediction are. This shows that the model that was trained on the 2020-04-01 to 2020-09-01 date range is less certain about its predictions four months after training compared to its predictions in the month immediately after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2020-09-01\", \"2020-10-01\", measure=\"ci_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2020-10-01\", \"2020-11-01\", measure=\"ci_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2020-11-01\", \"2020-12-01\", measure=\"ci_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2020-12-01\", \"2021-01-01\", measure=\"ci_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2021-01-01\", \"2021-02-01\", measure=\"ci_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "evaluate_on_timerange(\"2021-02-01\", \"2021-03-01\", measure=\"ci_width\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create one-hot-encoded leaf-node-assignments\n",
    "startdate = \"2021-02-01\"\n",
    "enddate = \"2021-03-01\"\n",
    "leaf_node_assignments = model.predict(batman_data_daterange(startdate, enddate)[feature_cols], pred_leaf=True)\n",
    "one_hot_leaf_nodes = oh_enc.transform(leaf_node_assignments)\n",
    "\n",
    "# labels\n",
    "y = batman_data_daterange(startdate, enddate)[\"is_fake_hotel\"].to_numpy()\n",
    "y_one_hot = y.reshape((-1, 1))\n",
    "y_one_hot = gt_oh_enc.transform(y_one_hot)\n",
    "y_hat, ci_widths = prediction_interval_vectorized(bayesian_fake_hotel_model, \n",
    "                                                  one_hot_leaf_nodes, \n",
    "                                                  instance_idx=range(len(one_hot_leaf_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "ax = sns.scatterplot(x=ci_widths, \n",
    "                y=y_hat, \n",
    "                hue=y, \n",
    "                alpha=0.25)\n",
    "ax.set(xlabel='Width of the 95%-interval of the posterior predictive distribution', \n",
    "       ylabel='The MLE of P(y=\"fake hotel\" | X)')\n",
    "ax.legend().set_title(\"Is fake hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "ax = sns.scatterplot(x=np.log10(ci_widths)[y==0], \n",
    "                y=np.log10(y_hat)[y==0],  \n",
    "                alpha=0.25)\n",
    "ax = sns.scatterplot(x=np.log10(ci_widths)[y==1], \n",
    "                y=np.log10(y_hat)[y==1],\n",
    "                alpha=0.5,\n",
    "                ax=ax\n",
    "                )\n",
    "ax.set(xlabel='Log - Width of the 95%-interval of the posterior predictive distribution', \n",
    "       ylabel='Log - The MLE of P(y=\"fake hotel\" | X)')\n",
    "ax.legend().set_title(\"Is fake hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_ci_width_distribution(model, x, labels):\n",
    "    preds_with_cis = prediction_interval_vectorized(\n",
    "        model, x, instance_idx=range(len(x))\n",
    "    )\n",
    "    ci_widths = preds_with_cis[1]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    for i, category in zip(range(2), ['Correct', 'Incorrect']):\n",
    "        ci_widths_category = ci_widths[get_correct_indices(model, x, labels)[i]]\n",
    "        mean_ci_width = np.mean(ci_widths_category)\n",
    "        num_samples = ci_widths_category.shape[0]\n",
    "        title = category + 'ly labelled ({:.1f}% of total)'.format(num_samples / x.shape[0] * 100)\n",
    "        axes[i].hist(ci_widths_category, weights=(1/num_samples)*np.ones(num_samples))\n",
    "        axes[i].annotate('Mean 95%-CI-width: {:.3f}'.format(mean_ci_width), (0.4, 0.9), ha='center')\n",
    "        axes[i].set_xlabel('95%-CI-width')\n",
    "        axes[i].set_ylim([0, 1])\n",
    "        axes[i].set_ylabel('Probability')\n",
    "        axes[i].set_title(title)       \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create one-hot-encoded leaf-node-assignments\n",
    "startdate = \"2021-01-01\"\n",
    "enddate = \"2021-02-01\"\n",
    "leaf_node_assignments = model.predict(batman_data_daterange(startdate, enddate)[feature_cols], pred_leaf=True)\n",
    "one_hot_leaf_nodes = oh_enc.transform(leaf_node_assignments)\n",
    "\n",
    "# labels\n",
    "y = batman_data_daterange(startdate, enddate)[\"is_fake_hotel\"].to_numpy()\n",
    "y_one_hot = y.reshape((-1, 1))\n",
    "y_one_hot = gt_oh_enc.transform(y_one_hot)\n",
    "y_hat, ci_widths = prediction_interval_vectorized(bayesian_fake_hotel_model, \n",
    "                                                  one_hot_leaf_nodes, \n",
    "                                                  instance_idx=range(len(one_hot_leaf_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "ax = sns.scatterplot(x=ci_widths, \n",
    "                y=y_hat, \n",
    "                hue=y, \n",
    "                alpha=0.25)\n",
    "ax.set(xlabel='Width of the 95%-interval of the posterior predictive distribution', \n",
    "       ylabel='The MLE of P(y=\"fake hotel\" | X)')\n",
    "ax.legend().set_title(\"Is fake hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "ax = sns.scatterplot(x=np.log10(ci_widths)[y==0], \n",
    "                y=np.log10(y_hat)[y==0],  \n",
    "                alpha=0.25)\n",
    "ax = sns.scatterplot(x=np.log10(ci_widths)[y==1], \n",
    "                y=np.log10(y_hat)[y==1],\n",
    "                alpha=0.5,\n",
    "                ax=ax\n",
    "                )\n",
    "ax.set(xlabel='Log - Width of the 95%-interval of the posterior predictive distribution', \n",
    "       ylabel='Log - The MLE of P(y=\"fake hotel\" | X)')\n",
    "ax.legend().set_title(\"Is fake hotel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### December"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create one-hot-encoded leaf-node-assignments\n",
    "startdate = \"2020-12-01\"\n",
    "enddate = \"2021-01-01\"\n",
    "leaf_node_assignments = model.predict(batman_data_daterange(startdate, enddate)[feature_cols], pred_leaf=True)\n",
    "one_hot_leaf_nodes = oh_enc.transform(leaf_node_assignments)\n",
    "\n",
    "# labels\n",
    "y = batman_data_daterange(startdate, enddate)[\"is_fake_hotel\"].to_numpy()\n",
    "y_one_hot = y.reshape((-1, 1))\n",
    "y_one_hot = gt_oh_enc.transform(y_one_hot)\n",
    "y_hat, ci_widths = prediction_interval_vectorized(bayesian_fake_hotel_model, \n",
    "                                                  one_hot_leaf_nodes, \n",
    "                                                  instance_idx=range(len(one_hot_leaf_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "ax = sns.scatterplot(x=ci_widths, \n",
    "                y=y_hat, \n",
    "                hue=y, \n",
    "                alpha=0.25)\n",
    "ax.set(xlabel='Width of the 95%-interval of the posterior predictive distribution', \n",
    "       ylabel='The MLE of P(y=\"fake hotel\" | X)')\n",
    "ax.legend().set_title(\"Is fake hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.rcParams[\"font.size\"] = 18\n",
    "\n",
    "ax = sns.scatterplot(x=np.log10(ci_widths)[y==0], \n",
    "                y=np.log10(y_hat)[y==0],  \n",
    "                alpha=0.25)\n",
    "ax = sns.scatterplot(x=np.log10(ci_widths)[y==1], \n",
    "                y=np.log10(y_hat)[y==1],\n",
    "                alpha=0.5,\n",
    "                ax=ax\n",
    "                )\n",
    "ax.set(xlabel='Log - Width of the 95%-interval of the posterior predictive distribution', \n",
    "       ylabel='Log - The MLE of P(y=\"fake hotel\" | X)')\n",
    "ax.legend().set_title(\"Is fake hotel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "This is merely a Proof-of-Concept of a Variational Bayesian model with uncertainty quantification of its predictions. There is still much more validation needed, and there are still many follow-up questions, such as:\n",
    "\n",
    "- are the data points with wide prediction intervals indeed the data points that are useful for manual review (in an active learning setup)\n",
    "- does the pattern of increasing uncertainty over time hold more generally, beyond the example shown above?\n",
    "- can an increase in prediction uncertainty be useful detection of model degradation as a result of concept drift already before we have our labels, or it is too unreliable for this use case?\n",
    "- how sensitive is the Variational model to number of trees in the tree ensemble?\n",
    "\n",
    "And many more. Yet, this notebook offers a first exploration and proof-of-concept of the topic and was as much as I managed to do in the timeframe of a single hackathon. I hope that in the adaptive ML task force we can continue to explore several of the questions that I formulated above, and that this notebook sparks some early feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Spark 2.4.4",
   "language": "python",
   "name": "spark244"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
